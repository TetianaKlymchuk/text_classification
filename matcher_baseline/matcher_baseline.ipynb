{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Message-matcher baseline model\n",
    "This communication contains a message matcher baseline model. Given a query text message and a corpus of historical messages, this matcher model retrieves all historical messages that are similar to the queried one. Your goal is to improve this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hashlib import md5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(path, tag):\n",
    "    '''\n",
    "    Creates a data frame for a given class\n",
    "    --------------------------------------\n",
    "    Input:\n",
    "        path (str): path where all classes folders are stored.\n",
    "        tag (str): name of the folder containing class \"tag\".\n",
    "    Output:\n",
    "        df (pd.DataFrame): dataframe with file as index and columns=[text, tag]\n",
    "    '''\n",
    "    list_of_text = []\n",
    "    tag_dir = os.path.join(path, tag)\n",
    "    for file in os.listdir(tag_dir):\n",
    "\n",
    "        with open(os.path.join(tag_dir, file), encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "            list_of_text.append((text, file))\n",
    "            df = pd.DataFrame(list_of_text, columns = ['Text', 'file'])\n",
    "            df = df.set_index('file')\n",
    "    df['tag'] = tag\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_dfs(path, tags):\n",
    "    '''\n",
    "    Loops over all classes in path, each in the corresponding folder\n",
    "    --------------------------------\n",
    "    Input:\n",
    "        path (str): path where all classes folders are stored.\n",
    "        tags (list): list of classes names.\n",
    "    Output:\n",
    "        df (pd.DataFrame): pandas dataframe with the dataframes corresponding to all classes concatenated.\n",
    "    '''\n",
    "    list_of_dfs = []\n",
    "    for tag in tags:\n",
    "\n",
    "        df = create_df(path, tag)\n",
    "        list_of_dfs.append(df)\n",
    "    data = pd.concat(list_of_dfs)\n",
    "    return data\n",
    "\n",
    "\n",
    "def to_md5(rsc_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert rcs_id string into a hexdigest md5.\n",
    "    :param rcs_id: str.\n",
    "    :return: hexdigext representation of md5 codification of input string.\n",
    "    \"\"\"\n",
    "    md5_rsc = bytes(rsc_id, 'utf-8')\n",
    "    result_1 = md5(md5_rsc)\n",
    "    return result_1.hexdigest()\n",
    "\n",
    "\n",
    "def get_similarity(resources: pd.DataFrame, space: str = 'tfidf', max_df: float = .75) -> np.array:\n",
    "    \"\"\"\n",
    "    Compute pairwise cosine similarity for resources in a given vector representation (tf or tfidf).\n",
    "    :param resources: pd.DataFrame with the resources as rows and at least 'Text' as column.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :param max_df: maximum valur for document frequency just as in sklearn Vectorizers.\n",
    "    :return: symmetric np.array with cosine similarity score for each resource pair.\n",
    "    \"\"\"\n",
    "    if space == 'tf':\n",
    "        vec = CountVectorizer(min_df=2, max_df=max_df)\n",
    "    elif space == 'tfidf':\n",
    "        vec = TfidfVectorizer(min_df=2, max_df=max_df)\n",
    "    else:\n",
    "        print('The \"space\" input must be either \"tf\" or \"tfidf\", using the default \"tfidf\" option...')\n",
    "        vec = TfidfVectorizer(min_df=2, max_df=max_df)\n",
    "    vec_res = vec.fit_transform(resources['Text'].fillna(''))\n",
    "    sims = cosine_similarity(vec_res, vec_res)\n",
    "    return sims\n",
    "\n",
    "\n",
    "def find_similar_rsc(similarity_scores: np.array, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a dictionary relating resources to a list of [resource, score] pairs per resource.\n",
    "    :param similarity_scores: matrix of similarity score per pair of resources of shape\n",
    "    (number of resoures, number of resources).\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :return: a pd.DataFrame with 'resource_idx', 'similar_res_idx' and 'similarity_score' as columns relating resources\n",
    "    to a given resource.\n",
    "    \"\"\"\n",
    "    similar_rsc_idx = np.where((similarity_scores >= threshold) & (similarity_scores < 0.999))\n",
    "    similar_scores = np.round(similarity_scores[similar_rsc_idx], 3)\n",
    "    sim_res = pd.DataFrame({'resource_idx': similar_rsc_idx[0],\n",
    "                            'similar_res_idx': similar_rsc_idx[1],\n",
    "                            'similarity_score': similar_scores})\n",
    "    return sim_res\n",
    "\n",
    "\n",
    "def get_similar_rsc(resources: pd.DataFrame, threshold: float = 0.75, space: str = 'tfidf') -> dict:\n",
    "    \"\"\"\n",
    "    Get similar resources per resource.\n",
    "    :param resources: pd.DataFrame with the resources as rows and at least 'Text' as column.\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :return: a dictionary with resources as keys and similar resources as values.\n",
    "    \"\"\"\n",
    "    sims = get_similarity(resources, space)\n",
    "    find_sims = find_similar_rsc(sims, threshold)\n",
    "    sim_df = find_sims.copy()\n",
    "    sim_df.reset_index(inplace=True)\n",
    "    sim_df['resource_id'] = resources['resource_id'].iloc[find_sims.resource_idx].values\n",
    "    sim_df['similar_res'] = resources['resource_id'].iloc[find_sims.similar_res_idx].values\n",
    "    sim_df['sim_resources'] = sim_df.apply(lambda x: [[x.similar_res, x.similarity_score]], axis=1)\n",
    "    grouped_sim_res = sim_df[['resource_id', 'sim_resources']].groupby('resource_id').agg(lambda x: np.sum(x))\n",
    "    similar_res_dict = grouped_sim_res.T.to_dict('records')[0]\n",
    "    sim_res = {k: sorted(v, key=lambda x: x[1], reverse=True) for k, v in similar_res_dict.items()}\n",
    "    return sim_res\n",
    "\n",
    "\n",
    "def get_similar(input_text: str, corpus: pd.DataFrame, threshold: float=0.75, space: str = 'tfidf') -> list:\n",
    "    \"\"\"\n",
    "    Retrieves a set of messages from a given corpus that are similar enough to an input message.\n",
    "    :param input_text: query text.\n",
    "    :param corpus: pd.DataFrame with historical messages as column 'Text'.\n",
    "    :param threshold: the similarity score threshold for retrieving as similar resource.\n",
    "    :param space: vector space representation of resources, either 'tf' or 'tfidf'.\n",
    "    :return: a list with all the similar messages content and corresponding score to the queried one.\n",
    "    \"\"\"\n",
    "    input_id = to_md5(input_text)\n",
    "    input_df = pd.DataFrame({'Text': [input_text], 'resource_id': [input_id]})\n",
    "    data = pd.concat([input_df, corpus])\n",
    "    sim_dict = get_similar_rsc(data, threshold, space)\n",
    "    result = list()\n",
    "    if sim_dict.get(input_id):\n",
    "        for sim_id, sim_score in sim_dict.get(input_id):\n",
    "            result.append([corpus['Text'][corpus['resource_id'] == sim_id].values[0], sim_score])\n",
    "    else:\n",
    "        result = [None, 0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing data\n",
    "\n",
    "From a given set of messages, a historical corpus and a query message are defined. Thus, the query message is fed into the message matcher so that all messages from the corpus similar to the query one are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../part1/dataset'\n",
    "tags = os.listdir(path)\n",
    "data_full = get_all_dfs(path, tags)[['Text']]\n",
    "data_full['resource_id'] = data_full['Text'].apply(to_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3467, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>resource_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61164</th>\n",
       "      <td>\\nIn article &lt;C5t05K.DB6@research.canon.oz.au&gt;...</td>\n",
       "      <td>a5cd714b0c79776cbf25ce0b9faeef47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102597</th>\n",
       "      <td>\\nIn article &lt;12718@news.duke.edu&gt; fierkelab@b...</td>\n",
       "      <td>39af238a890c32b5cbcd8f4c05f84e19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176853</th>\n",
       "      <td>Article-I.D.: shelley.1pqi26INNl8j\\n\\ndreitman...</td>\n",
       "      <td>d0e662fc665382bc408cc2deda86c9d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104794</th>\n",
       "      <td>\\n\\n\\nI hate to be rude, but screw the seating...</td>\n",
       "      <td>5d43851150305698729229bdff0e360b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54440</th>\n",
       "      <td>\\nFrom article &lt;1993Apr18.001319.2340@gnv.ifas...</td>\n",
       "      <td>36b1552e3d8ce7218f27bc59c650461e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "file                                                        \n",
       "61164   \\nIn article <C5t05K.DB6@research.canon.oz.au>...   \n",
       "102597  \\nIn article <12718@news.duke.edu> fierkelab@b...   \n",
       "176853  Article-I.D.: shelley.1pqi26INNl8j\\n\\ndreitman...   \n",
       "104794  \\n\\n\\nI hate to be rude, but screw the seating...   \n",
       "54440   \\nFrom article <1993Apr18.001319.2340@gnv.ifas...   \n",
       "\n",
       "                             resource_id  \n",
       "file                                      \n",
       "61164   a5cd714b0c79776cbf25ce0b9faeef47  \n",
       "102597  39af238a890c32b5cbcd8f4c05f84e19  \n",
       "176853  d0e662fc665382bc408cc2deda86c9d0  \n",
       "104794  5d43851150305698729229bdff0e360b  \n",
       "54440   36b1552e3d8ce7218f27bc59c650461e  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = data_full.sample(int(data_full.shape[0] * 0.9))\n",
    "test_data = data_full[~data_full.resource_id.isin(corpus.resource_id)]\n",
    "print(corpus.shape)\n",
    "corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom article <1993Apr18.001319.2340@gnv.ifas.ufl.edu>, by jrm@gnv.ifas.ufl.edu:\\n> Yea, there are millions of cases where yoy *say* that firearms\\n> \\'deter\\' criminals. Alas, this is not provable. I think that that\\n> there are actually *few* cases where this is so. \\n\\nIt certainly is provable.  Around a million Americans every year defend\\nthemselves with firearms.  In many of these cases the defender doesn\\'t even\\nhave to fire a shot!  The mere presence of a gun is oftentimes all the\\ndeterrent that is needed.\\n\\nI don\\'t like violence anymore than anyone else does.  But, taking away the\\nright of Americans to keep and bear arms is not the solution to the violent\\ncrime problem in this country.  If honest, law-abiding citizens are unable\\nto get firearms then they will be preyed on even more by criminals who will\\nbe able to acquire guns through illegal channels.  Expect to start seeing\\nthe crime syndicates who smuggle drugs into this country start smuggling\\nguns.  Believe me this will happen.  There is *plenty* of economic\\nincentive for gangsters to illegaly import guns into this country if guns\\nshould be banned by the Klintonistas.\\n\\n> The bulk of firarems are used against unworthy and unnesessary\\n> opponents ... those who posessa a cool jakcet you want, those who\\n> would argue with you about a parking space, those who would\\n> take your woman. In short, trivial and worthless causes.\\n\\nStatistics, por favor?\\n\\n> Too much of this has ruined you cause. There is no recovery. \\n> In the near future, federal martials will come for your arms.\\n> No one will help you. You are more dangerous, to their thinking,\\n> than the \\'criminal\\'. This is your own fault. \\n\\nSee my previous post.  That ought to set you straight.\\n\\n> The 2nd amendment is dead. Accept this. Find another way.\\n\\nPeople have the right to keep and bear arms no matter what the\\nConstitution says.  That means that even if the 2nd Amendment is\\nrepealed the *people* (that\\'s all American citizens FYI) will *still*\\nhave the right to keep and bear arms.\\n\\n\\nScott Kennedy,  Brewer and Patriot\\n\\n          the Bible through the barrel of a gun...\"  --ATF spokesman\\n          [the Constitution] through the barrel of a gun...\"  --Me\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.tail(2).Text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting similar messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Since this posting, I've received no replies or followups, so I'm posting\n",
      "here hoping for the feedback I didn't get in rec.audio.car:\n",
      "\n",
      "article number - 9855\n",
      "\n",
      "I recently saw a particular third party antenna on a new Camry (not mine,\n",
      "but it caught my interest) and a new 626.  It seems to replace the\n",
      "factory power antenna and is about a foot long made of plastic tubing.  I\n",
      "have seen them on quite a few cars, but I can't find anything more about\n",
      "them in previous r.a.c articles nor in r.a articles.\n",
      "\n",
      "I'd like to know all I can, so any feedback is greatly appreciated.\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\"Mom, we're hungry!\" - Bud Bundy        \"Why tell me?\" - Peg Bundy\n",
      "\n",
      "Vincent Lai\n",
      "\n",
      "vinlai@cbnewsb.att.com forwards mail to\n",
      "vlai@attmail.com which eventually winds up in\n",
      "wcmnja!lai@somerset.att.com\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_text = test_data.iloc[42]['Text']\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_results = get_similar(query_text, corpus, 0.2)\n",
    "if similar_results[0]:\n",
    "    print(\"Similar Messages:\")\n",
    "    for result in similar_results:\n",
    "        print(\"-\"*75)\n",
    "        print(result[0])\n",
    "        print(f\"Similarity score: {result[1]}\")\n",
    "        print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uic",
   "language": "python",
   "name": "uic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
